# 相機內外參解析格式與使用說明

## 概述

本文檔說明相機標定工具產生的內外參數據格式，以及如何使用這些參數進行像素座標到世界座標的轉換。

## 工具產生的檔案格式

### 1. 內參標定工具導出格式

#### NPY格式檔案
- `camera_matrix_YYYYMMDD_HHMMSS.npy` - 相機內參矩陣
- `dist_coeffs_YYYYMMDD_HHMMSS.npy` - 畸變係數

#### JSON格式檔案
- `calibration_data_YYYYMMDD_HHMMSS.json` - 完整標定資料

```json
{
  "camera_matrix": [
    [fx, 0, cx],
    [0, fy, cy],
    [0, 0, 1]
  ],
  "distortion_coefficients": [k1, k2, p1, p2, k3],
  "reprojection_error": 0.234,
  "checkerboard_size": [17, 12],
  "square_size_cm": 1.0,
  "timestamp": "20241210_143022",
  "num_images": 25
}
```

### 2. 外參調整工具導出格式

#### NPY格式檔案
```python
# 外參字典格式
{
  'rvec': [[rx], [ry], [rz]],  # 旋轉向量 (3x1)
  'tvec': [[tx], [ty], [tz]],  # 平移向量 (3x1)
  'algorithm': 'PnP_ITERATIVE',
  'timestamp': '20241210_143530'
}
```

#### JSON格式檔案
```json
{
  "rotation_vector": [[rx], [ry], [rz]],
  "translation_vector": [[tx], [ty], [tz]], 
  "algorithm": "PnP_ITERATIVE",
  "timestamp": "20241210_143530"
}
```

## 數學原理與轉換過程

### 針孔相機模型

相機成像遵循針孔相機模型，其中內參矩陣 K 定義為：

```
K = [fx   0  cx]
    [ 0  fy  cy]
    [ 0   0   1]
```

其中：
- fx, fy：焦距（像素單位）
- cx, cy：主點座標（光軸與像平面交點）

### 畸變模型

徑向畸變和切向畸變由5個參數描述：

```
[x_corrected] = [x] * (1 + k1*r² + k2*r⁴ + k3*r⁶) + [2*p1*x*y + p2*(r²+2*x²)]
[y_corrected]   [y]                                     [p1*(r²+2*y²) + 2*p2*x*y]
```

其中：
- k1, k2, k3：徑向畸變係數
- p1, p2：切向畸變係數
- r² = x² + y²

### 外參變換

外參描述相機座標系與世界座標系的關係：

```
[X_cam]     [X_world]
[Y_cam] = R [Y_world] + t
[Z_cam]     [Z_world]
```

其中：
- R：旋轉矩陣（由旋轉向量 rvec 通過 Rodrigues 公式計算）
- t：平移向量

旋轉向量轉旋轉矩陣（Rodrigues公式）：
```
R = I + (sin(θ)/θ) * K + ((1-cos(θ))/θ²) * K²
```

其中 θ = ||rvec||，K 是 rvec 的反對稱矩陣。

## 像素座標到世界座標轉換（Z=0平面）

### 步驟一：圖像去畸變

使用OpenCV的`undistortPoints`函數：

```python
import cv2
import numpy as np

# 去畸變處理
undistorted_points = cv2.undistortPoints(
    pixel_coords.reshape(1, 1, 2), 
    camera_matrix, 
    dist_coeffs, 
    P=camera_matrix
).reshape(-1, 2)
```

### 步驟二：歸一化座標計算

```
[X_norm]       [u]
[Y_norm] = K⁻¹ [v]
[  1   ]       [1]
```

```python
# 計算歸一化座標
uv_homogeneous = np.array([u, v, 1.0])
normalized_coords = np.linalg.inv(camera_matrix) @ uv_homogeneous
```

### 步驟三：計算深度係數

假設世界座標系中 Z_world = 0：

```
s = (-t_z) / (R₃ · [X_norm, Y_norm, 1]ᵀ)
```

其中 R₃ 是旋轉矩陣的第三行。

### 步驟四：世界座標計算

```
[X_world]         [X_norm]
[Y_world] = R⁻¹ * (s * [Y_norm] - t)
[   0   ]         [  1   ]
```

## 完整實現程式碼

```python
import cv2
import numpy as np
import json

class CameraCoordinateTransformer:
    def __init__(self, camera_matrix, dist_coeffs, rvec, tvec):
        """
        初始化座標轉換器
        
        Args:
            camera_matrix (np.array): 3x3 內參矩陣
            dist_coeffs (np.array): 5x1 畸變係數
            rvec (np.array): 3x1 旋轉向量
            tvec (np.array): 3x1 平移向量
        """
        self.K = camera_matrix
        self.D = dist_coeffs
        self.rvec = rvec.reshape(3, 1) if rvec.shape != (3, 1) else rvec
        self.tvec = tvec.reshape(3, 1) if tvec.shape != (3, 1) else tvec
        
        # 計算旋轉矩陣
        self.R, _ = cv2.Rodrigues(self.rvec)
        
    @classmethod
    def from_files(cls, intrinsic_file, extrinsic_file):
        """
        從檔案載入參數
        
        Args:
            intrinsic_file: 內參檔案路徑（JSON或NPY）
            extrinsic_file: 外參檔案路徑（JSON或NPY）
        """
        # 載入內參
        if intrinsic_file.endswith('.json'):
            with open(intrinsic_file, 'r') as f:
                intrinsic_data = json.load(f)
            camera_matrix = np.array(intrinsic_data['camera_matrix'])
            dist_coeffs = np.array(intrinsic_data['distortion_coefficients'])
        else:
            camera_matrix = np.load(intrinsic_file)
            # 假設畸變係數檔案名稱相似
            dist_file = intrinsic_file.replace('camera_matrix', 'dist_coeffs')
            dist_coeffs = np.load(dist_file)
            
        # 載入外參
        if extrinsic_file.endswith('.json'):
            with open(extrinsic_file, 'r') as f:
                extrinsic_data = json.load(f)
            rvec = np.array(extrinsic_data['rotation_vector'])
            tvec = np.array(extrinsic_data['translation_vector'])
        else:
            extrinsic_data = np.load(extrinsic_file, allow_pickle=True).item()
            rvec = extrinsic_data['rvec']
            tvec = extrinsic_data['tvec']
            
        return cls(camera_matrix, dist_coeffs, rvec, tvec)
    
    def pixel_to_world(self, pixel_coords):
        """
        像素座標轉世界座標（假設Z=0平面）
        
        Args:
            pixel_coords: [u, v] 或 [[u1,v1], [u2,v2], ...] 像素座標
            
        Returns:
            world_coords: [x, y] 或 [[x1,y1], [x2,y2], ...] 世界座標
        """
        pixel_coords = np.array(pixel_coords)
        if pixel_coords.ndim == 1:
            pixel_coords = pixel_coords.reshape(1, -1)
            
        world_points = []
        
        for uv in pixel_coords:
            # 步驟1：去畸變
            undistorted_uv = cv2.undistortPoints(
                uv.reshape(1, 1, 2), self.K, self.D, P=self.K
            ).reshape(-1)
            
            # 步驟2：歸一化座標
            uv_homogeneous = np.array([undistorted_uv[0], undistorted_uv[1], 1.0])
            normalized_coords = np.linalg.inv(self.K) @ uv_homogeneous
            
            # 步驟3：計算深度係數（Z=0平面）
            denominator = self.R[2] @ normalized_coords
            if abs(denominator) < 1e-8:
                raise ValueError("相機平行於Z=0平面，無法計算交點")
                
            s = (0 - self.tvec[2, 0]) / denominator
            
            # 步驟4：計算世界座標
            camera_point = s * normalized_coords
            world_point = np.linalg.inv(self.R) @ (camera_point - self.tvec.ravel())
            
            world_points.append(world_point[:2])  # 只返回X,Y座標
            
        return np.array(world_points).squeeze()
    
    def world_to_pixel(self, world_coords):
        """
        世界座標轉像素座標
        
        Args:
            world_coords: [x, y] 或 [[x1,y1], [x2,y2], ...] 世界座標
            
        Returns:
            pixel_coords: [u, v] 或 [[u1,v1], [u2,v2], ...] 像素座標
        """
        world_coords = np.array(world_coords)
        if world_coords.ndim == 1:
            world_coords = world_coords.reshape(1, -1)
            
        # 添加Z=0座標
        world_points_3d = np.column_stack([world_coords, np.zeros(len(world_coords))])
        
        # 使用OpenCV投影
        pixel_points, _ = cv2.projectPoints(
            world_points_3d.astype(np.float32),
            self.rvec, self.tvec, self.K, self.D
        )
        
        return pixel_points.reshape(-1, 2).squeeze()

# 使用範例
if __name__ == "__main__":
    # 方法1：直接載入檔案
    transformer = CameraCoordinateTransformer.from_files(
        'calibration_data_20241210_143022.json',
        'extrinsic_20241210_143530.json'
    )
    
    # 方法2：手動載入參數
    K = np.array([[1000, 0, 320], [0, 1000, 240], [0, 0, 1]])
    D = np.array([0.1, -0.2, 0.001, 0.002, 0.05])
    rvec = np.array([[0.1], [0.2], [0.3]])
    tvec = np.array([[100], [200], [500]])
    
    transformer = CameraCoordinateTransformer(K, D, rvec, tvec)
    
    # 轉換單個點
    pixel_point = [320, 240]
    world_point = transformer.pixel_to_world(pixel_point)
    print(f"像素座標 {pixel_point} 對應世界座標 {world_point}")
    
    # 轉換多個點
    pixel_points = [[100, 200], [400, 300], [320, 240]]
    world_points = transformer.pixel_to_world(pixel_points)
    print(f"批量轉換結果:\n{world_points}")
    
    # 反向轉換驗證
    back_to_pixels = transformer.world_to_pixel(world_points)
    print(f"反向轉換驗證:\n{back_to_pixels}")
```

## 注意事項

### 1. 座標系假設
- 世界座標系假設Z=0平面（所有物體在同一平面上）
- 如需處理3D物體，需修改演算法

### 2. 參數檔案格式
- NPY檔案：使用`np.load()`載入，注意`allow_pickle=True`
- JSON檔案：標準JSON格式，數值為列表格式

### 3. 精度考量
- 畸變校正精度影響最終結果
- 外參估算品質直接影響轉換準確度
- 建議使用充足的標定圖像（>20張）

### 4. 錯誤處理
- 檢查相機是否平行於工作平面
- 驗證檔案格式正確性
- 處理數值計算異常

### 5. 座標轉換驗證
建議使用已知世界座標的點位進行反向驗證：

```python
# 驗證轉換精度
known_world_points = [[10.0, 20.0], [50.0, 30.0]]
projected_pixels = transformer.world_to_pixel(known_world_points)
recovered_world = transformer.pixel_to_world(projected_pixels)

error = np.linalg.norm(known_world_points - recovered_world, axis=1)
print(f"轉換誤差: {error} mm")
```

## 常見問題排除

### Q1: 轉換結果異常大或異常小
**A**: 檢查單位一致性，確認標定時的格子大小單位與期望的世界座標單位一致。

### Q2: 畸變校正後座標偏移
**A**: 確認畸變係數載入正確，檢查內參矩陣的主點位置。

### Q3: 外參載入格式錯誤
**A**: 確認旋轉向量和平移向量的維度正確（3x1或1x3），必要時進行reshape。

### Q4: 計算結果與實際測量不符
**A**: 檢查標定品質，增加標定圖像數量，確保標定圖像覆蓋整個感興趣區域。