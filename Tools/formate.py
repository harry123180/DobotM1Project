#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NPYæ ¼å¼è¨ºæ–·å·¥å…·
ç”¨æ–¼åˆ†æå’Œè¨ºæ–·NPYæª”æ¡ˆçš„æ ¼å¼çµæ§‹
"""

import numpy as np
import os
import sys
from pathlib import Path

class NPYFormatReader:
    def __init__(self):
        self.supported_formats = {
            'camera_matrix': self.analyze_camera_matrix,
            'dist_coeffs': self.analyze_distortion_coeffs, 
            'extrinsic': self.analyze_extrinsic,
            'corner_points': self.analyze_corner_points,
            'world_points': self.analyze_world_points,
            'generic': self.analyze_generic
        }
    
    def analyze_file(self, file_path):
        """åˆ†æNPYæª”æ¡ˆ"""
        if not os.path.exists(file_path):
            print(f"éŒ¯èª¤: æª”æ¡ˆä¸å­˜åœ¨ - {file_path}")
            return False
        
        try:
            print(f"\n{'='*60}")
            print(f"åˆ†ææª”æ¡ˆ: {file_path}")
            print(f"{'='*60}")
            
            # è¼‰å…¥æ•¸æ“š
            data = np.load(file_path, allow_pickle=True)
            
            # åŸºæœ¬è³‡è¨Š
            print(f"æ•¸æ“šé¡å‹: {type(data)}")
            print(f"numpy dtype: {data.dtype}")
            print(f"æ•¸çµ„å½¢ç‹€: {data.shape}")
            print(f"æ•¸çµ„å¤§å°: {data.size}")
            print(f"è¨˜æ†¶é«”ä½”ç”¨: {data.nbytes} bytes")
            
            # æ ¹æ“šæª”æ¡ˆåæ¨æ¸¬æ ¼å¼é¡å‹
            file_name = Path(file_path).stem.lower()
            format_type = self.detect_format_type(file_name, data)
            
            print(f"æ¨æ¸¬æ ¼å¼: {format_type}")
            print(f"{'-'*40}")
            
            # åŸ·è¡Œç‰¹å®šåˆ†æ
            if format_type in self.supported_formats:
                self.supported_formats[format_type](data, file_path)
            else:
                self.analyze_generic(data, file_path)
                
            return True
            
        except Exception as e:
            print(f"éŒ¯èª¤: ç„¡æ³•è®€å–æª”æ¡ˆ - {str(e)}")
            return False
    
    def detect_format_type(self, file_name, data):
        """æ ¹æ“šæª”æ¡ˆåå’Œæ•¸æ“šç‰¹å¾µæ¨æ¸¬æ ¼å¼é¡å‹"""
        if 'camera_matrix' in file_name or 'intrinsic' in file_name:
            return 'camera_matrix'
        elif 'dist' in file_name or 'distortion' in file_name:
            return 'dist_coeffs'
        elif 'extrinsic' in file_name or 'external' in file_name:
            return 'extrinsic'
        elif 'corner' in file_name or 'image' in file_name:
            return 'corner_points'
        elif 'world' in file_name or 'real' in file_name:
            return 'world_points'
        else:
            # æ ¹æ“šæ•¸æ“šç‰¹å¾µæ¨æ¸¬
            if data.shape == (3, 3):
                return 'camera_matrix'
            elif data.size == 5:
                return 'dist_coeffs'
            elif data.dtype == object:
                return 'extrinsic'
            elif len(data.shape) == 2 and data.shape[1] == 3:
                return 'corner_points'
            else:
                return 'generic'
    
    def analyze_camera_matrix(self, data, file_path):
        """åˆ†æç›¸æ©Ÿå…§åƒçŸ©é™£"""
        print("ğŸ“· ç›¸æ©Ÿå…§åƒçŸ©é™£åˆ†æ")
        print(f"{'-'*30}")
        
        if data.shape != (3, 3):
            print(f"âš ï¸  è­¦å‘Š: å½¢ç‹€ä¸æ­£ç¢ºï¼Œæ‡‰ç‚º(3,3)ï¼Œå¯¦éš›ç‚º{data.shape}")
            return
        
        print("å…§åƒçŸ©é™£:")
        print(data)
        print()
        
        # æå–åƒæ•¸
        fx = data[0, 0]
        fy = data[1, 1] 
        cx = data[0, 2]
        cy = data[1, 2]
        skew = data[0, 1]
        
        print(f"ç„¦è· fx: {fx:.2f}")
        print(f"ç„¦è· fy: {fy:.2f}")
        print(f"ä¸»é» cx: {cx:.2f}")
        print(f"ä¸»é» cy: {cy:.2f}")
        print(f"åæ–œ skew: {skew:.6f}")
        
        # æª¢æŸ¥åˆç†æ€§
        if fx <= 0 or fy <= 0:
            print("âŒ éŒ¯èª¤: ç„¦è·æ‡‰ç‚ºæ­£å€¼")
        if abs(fx - fy) / max(fx, fy) > 0.1:
            print("âš ï¸  è­¦å‘Š: fxå’Œfyå·®ç•°è¼ƒå¤§ï¼Œå¯èƒ½ä¸æ­£å¸¸")
        if abs(skew) > 1:
            print("âš ï¸  è­¦å‘Š: åæ–œå€¼è¼ƒå¤§ï¼Œé€šå¸¸æ‡‰æ¥è¿‘0")
        
        print(f"âœ… æ ¼å¼: æ¨™æº–3x3ç›¸æ©Ÿå…§åƒçŸ©é™£")
    
    def analyze_distortion_coeffs(self, data, file_path):
        """åˆ†æç•¸è®Šä¿‚æ•¸"""
        print("ğŸ”§ ç•¸è®Šä¿‚æ•¸åˆ†æ")
        print(f"{'-'*30}")
        
        # æª¢æŸ¥ä¸¦èª¿æ•´å½¢ç‹€
        original_shape = data.shape
        if data.shape == (1, 5):
            data = data.ravel()
        elif data.shape == (5, 1):
            data = data.ravel()
        elif data.shape != (5,):
            print(f"âŒ éŒ¯èª¤: å½¢ç‹€ä¸æ­£ç¢ºï¼Œæ‡‰ç‚º(5,)ã€(1,5)æˆ–(5,1)ï¼Œå¯¦éš›ç‚º{original_shape}")
            return
        
        print(f"åŸå§‹å½¢ç‹€: {original_shape}")
        print(f"èª¿æ•´å¾Œå½¢ç‹€: {data.shape}")
        print()
        
        print("ç•¸è®Šä¿‚æ•¸:")
        print(data)
        print()
        
        # æ¨™è¨˜åƒæ•¸
        k1, k2, p1, p2, k3 = data
        print(f"k1 (å¾‘å‘ç•¸è®Š1): {k1:.8f}")
        print(f"k2 (å¾‘å‘ç•¸è®Š2): {k2:.8f}")
        print(f"p1 (åˆ‡å‘ç•¸è®Š1): {p1:.8f}")
        print(f"p2 (åˆ‡å‘ç•¸è®Š2): {p2:.8f}")
        print(f"k3 (å¾‘å‘ç•¸è®Š3): {k3:.8f}")
        
        # æª¢æŸ¥åˆç†æ€§
        if abs(k1) > 1:
            print("âš ï¸  è­¦å‘Š: k1å€¼è¼ƒå¤§ï¼Œå¯èƒ½ç•°å¸¸")
        if abs(k2) > 1:
            print("âš ï¸  è­¦å‘Š: k2å€¼è¼ƒå¤§ï¼Œå¯èƒ½ç•°å¸¸")
        if abs(p1) > 0.1 or abs(p2) > 0.1:
            print("âš ï¸  è­¦å‘Š: åˆ‡å‘ç•¸è®Šå€¼è¼ƒå¤§")
        
        print(f"âœ… æ ¼å¼: æ¨™æº–5åƒæ•¸ç•¸è®Šä¿‚æ•¸")
    
    def analyze_extrinsic(self, data, file_path):
        """åˆ†æå¤–åƒæ•¸æ“š"""
        print("ğŸ¯ å¤–åƒæ•¸æ“šåˆ†æ")
        print(f"{'-'*30}")
        
        if data.dtype != object:
            print(f"âŒ éŒ¯èª¤: æ‡‰ç‚ºobjecté¡å‹ï¼Œå¯¦éš›ç‚º{data.dtype}")
            return
        
        # å˜—è©¦æå–å­—å…¸
        try:
            if data.shape == ():
                # æ¨™é‡objectï¼Œé€šå¸¸æ˜¯å­—å…¸
                extrinsic_dict = data.item()
            else:
                extrinsic_dict = data
            
            print(f"æ•¸æ“šé¡å‹: {type(extrinsic_dict)}")
            
            if isinstance(extrinsic_dict, dict):
                print("åŒ…å«çš„éµå€¼:")
                for key in extrinsic_dict.keys():
                    print(f"  - {key}: {type(extrinsic_dict[key])}")
                print()
                
                # æª¢æŸ¥å¿…è¦çš„éµ
                required_keys = ['rvec', 'tvec']
                missing_keys = [key for key in required_keys if key not in extrinsic_dict]
                
                if missing_keys:
                    print(f"âŒ éŒ¯èª¤: ç¼ºå°‘å¿…è¦éµå€¼: {missing_keys}")
                    return
                
                # åˆ†ææ—‹è½‰å‘é‡
                rvec = extrinsic_dict['rvec']
                print(f"æ—‹è½‰å‘é‡ rvec:")
                print(f"  å½¢ç‹€: {rvec.shape}")
                print(f"  æ•¸å€¼:")
                print(f"    rx: {rvec[0, 0]:.6f}")
                print(f"    ry: {rvec[1, 0]:.6f}")
                print(f"    rz: {rvec[2, 0]:.6f}")
                
                # åˆ†æå¹³ç§»å‘é‡
                tvec = extrinsic_dict['tvec']
                print(f"å¹³ç§»å‘é‡ tvec:")
                print(f"  å½¢ç‹€: {tvec.shape}")
                print(f"  æ•¸å€¼:")
                print(f"    tx: {tvec[0, 0]:.6f}")
                print(f"    ty: {tvec[1, 0]:.6f}")
                print(f"    tz: {tvec[2, 0]:.6f}")
                
                # æª¢æŸ¥å…¶ä»–å¯é¸éµ
                optional_keys = ['algorithm', 'timestamp', 'error']
                for key in optional_keys:
                    if key in extrinsic_dict:
                        print(f"{key}: {extrinsic_dict[key]}")
                
                print(f"âœ… æ ¼å¼: æ¨™æº–å¤–åƒå­—å…¸æ ¼å¼")
            else:
                print(f"âŒ éŒ¯èª¤: æœŸæœ›å­—å…¸é¡å‹ï¼Œå¯¦éš›ç‚º{type(extrinsic_dict)}")
                
        except Exception as e:
            print(f"âŒ éŒ¯èª¤: ç„¡æ³•è§£æå¤–åƒæ•¸æ“š - {str(e)}")
    
    def analyze_corner_points(self, data, file_path):
        """åˆ†æè§’é»æ•¸æ“š"""
        print("ğŸ“ è§’é»æ•¸æ“šåˆ†æ")
        print(f"{'-'*30}")
        
        if len(data.shape) != 2:
            print(f"âŒ éŒ¯èª¤: æ‡‰ç‚º2Dæ•¸çµ„ï¼Œå¯¦éš›ç‚º{len(data.shape)}D")
            return
        
        if data.shape[1] != 3:
            print(f"âŒ éŒ¯èª¤: ç¬¬äºŒç¶­æ‡‰ç‚º3 [id, x, y]ï¼Œå¯¦éš›ç‚º{data.shape[1]}")
            return
        
        print(f"é»ä½æ•¸é‡: {data.shape[0]}")
        print(f"æ•¸æ“šæ ¼å¼: [id, image_x, image_y]")
        print()
        
        # é¡¯ç¤ºå‰å¹¾å€‹é»
        display_count = min(5, data.shape[0])
        print(f"å‰{display_count}å€‹é»ä½:")
        print("ID\tåœ–åƒX\tåœ–åƒY")
        print("-" * 30)
        for i in range(display_count):
            print(f"{data[i, 0]:.0f}\t{data[i, 1]:.1f}\t{data[i, 2]:.1f}")
        
        if data.shape[0] > display_count:
            print(f"... (é‚„æœ‰{data.shape[0] - display_count}å€‹é»ä½)")
        
        # çµ±è¨ˆè³‡è¨Š
        ids = data[:, 0]
        x_coords = data[:, 1]
        y_coords = data[:, 2]
        
        print(f"\nçµ±è¨ˆè³‡è¨Š:")
        print(f"IDç¯„åœ: {ids.min():.0f} ~ {ids.max():.0f}")
        print(f"Xåº§æ¨™ç¯„åœ: {x_coords.min():.1f} ~ {x_coords.max():.1f}")
        print(f"Yåº§æ¨™ç¯„åœ: {y_coords.min():.1f} ~ {y_coords.max():.1f}")
        
        # æª¢æŸ¥IDå”¯ä¸€æ€§
        unique_ids = np.unique(ids)
        if len(unique_ids) != len(ids):
            print(f"âš ï¸  è­¦å‘Š: IDæœ‰é‡è¤‡ï¼Œå”¯ä¸€IDæ•¸é‡: {len(unique_ids)}")
        
        print(f"âœ… æ ¼å¼: æ¨™æº–è§’é»æ•¸æ“šæ ¼å¼")
    
    def analyze_world_points(self, data, file_path):
        """åˆ†æä¸–ç•Œåº§æ¨™æ•¸æ“š"""
        print("ğŸŒ ä¸–ç•Œåº§æ¨™æ•¸æ“šåˆ†æ")
        print(f"{'-'*30}")
        
        if len(data.shape) != 2:
            print(f"âŒ éŒ¯èª¤: æ‡‰ç‚º2Dæ•¸çµ„ï¼Œå¯¦éš›ç‚º{len(data.shape)}D")
            return
        
        if data.shape[1] != 3:
            print(f"âŒ éŒ¯èª¤: ç¬¬äºŒç¶­æ‡‰ç‚º3 [id, x, y]ï¼Œå¯¦éš›ç‚º{data.shape[1]}")
            return
        
        print(f"é»ä½æ•¸é‡: {data.shape[0]}")
        print(f"æ•¸æ“šæ ¼å¼: [id, world_x, world_y]")
        print()
        
        # é¡¯ç¤ºå‰å¹¾å€‹é»
        display_count = min(5, data.shape[0])
        print(f"å‰{display_count}å€‹é»ä½:")
        print("ID\tä¸–ç•ŒX\tä¸–ç•ŒY")
        print("-" * 30)
        for i in range(display_count):
            print(f"{data[i, 0]:.0f}\t{data[i, 1]:.1f}\t{data[i, 2]:.1f}")
        
        if data.shape[0] > display_count:
            print(f"... (é‚„æœ‰{data.shape[0] - display_count}å€‹é»ä½)")
        
        # çµ±è¨ˆè³‡è¨Š
        ids = data[:, 0]
        x_coords = data[:, 1]
        y_coords = data[:, 2]
        
        print(f"\nçµ±è¨ˆè³‡è¨Š:")
        print(f"IDç¯„åœ: {ids.min():.0f} ~ {ids.max():.0f}")
        print(f"Xåº§æ¨™ç¯„åœ: {x_coords.min():.1f} ~ {x_coords.max():.1f}")
        print(f"Yåº§æ¨™ç¯„åœ: {y_coords.min():.1f} ~ {y_coords.max():.1f}")
        
        # æª¢æŸ¥IDå”¯ä¸€æ€§
        unique_ids = np.unique(ids)
        if len(unique_ids) != len(ids):
            print(f"âš ï¸  è­¦å‘Š: IDæœ‰é‡è¤‡ï¼Œå”¯ä¸€IDæ•¸é‡: {len(unique_ids)}")
        
        print(f"âœ… æ ¼å¼: æ¨™æº–ä¸–ç•Œåº§æ¨™æ•¸æ“šæ ¼å¼")
    
    def analyze_generic(self, data, file_path):
        """é€šç”¨æ•¸æ“šåˆ†æ"""
        print("ğŸ” é€šç”¨æ•¸æ“šåˆ†æ")
        print(f"{'-'*30}")
        
        print(f"é€™æ˜¯ä¸€å€‹æœªè­˜åˆ¥çš„æ•¸æ“šæ ¼å¼")
        print()
        
        # é¡¯ç¤ºæ•¸æ“šå…§å®¹ï¼ˆæœ‰é™åˆ¶ï¼‰
        if data.size <= 50:
            print("å®Œæ•´æ•¸æ“šå…§å®¹:")
            print(data)
        else:
            print("æ•¸æ“šå…§å®¹é è¦½:")
            if len(data.shape) == 1:
                print(f"å‰10å€‹å…ƒç´ : {data[:10]}")
            elif len(data.shape) == 2:
                print(f"å‰5è¡Œ:")
                print(data[:5])
            else:
                print("æ•¸æ“šçµæ§‹è¤‡é›œï¼Œå»ºè­°æ‰‹å‹•æª¢æŸ¥")
        
        # æ•¸å€¼çµ±è¨ˆï¼ˆå¦‚æœæ˜¯æ•¸å€¼å‹ï¼‰
        if np.issubdtype(data.dtype, np.number):
            print(f"\næ•¸å€¼çµ±è¨ˆ:")
            print(f"æœ€å°å€¼: {np.min(data)}")
            print(f"æœ€å¤§å€¼: {np.max(data)}")
            print(f"å¹³å‡å€¼: {np.mean(data):.6f}")
            print(f"æ¨™æº–å·®: {np.std(data):.6f}")
    
    def analyze_directory(self, dir_path):
        """åˆ†æç›®éŒ„ä¸­çš„æ‰€æœ‰NPYæª”æ¡ˆ"""
        if not os.path.isdir(dir_path):
            print(f"éŒ¯èª¤: ç›®éŒ„ä¸å­˜åœ¨ - {dir_path}")
            return
        
        npy_files = list(Path(dir_path).glob("*.npy"))
        
        if not npy_files:
            print(f"ç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°NPYæª”æ¡ˆ: {dir_path}")
            return
        
        print(f"æ‰¾åˆ° {len(npy_files)} å€‹NPYæª”æ¡ˆ")
        print("="*60)
        
        for npy_file in sorted(npy_files):
            self.analyze_file(str(npy_file))
            print("\n")

def main():
    """ä¸»å‡½æ•¸"""
    reader = NPYFormatReader()
    
    if len(sys.argv) < 2:
        print("NPYæ ¼å¼è¨ºæ–·å·¥å…·")
        print("="*40)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python npy_format_read.py <æª”æ¡ˆè·¯å¾‘>")
        print("  python npy_format_read.py <ç›®éŒ„è·¯å¾‘>")
        print()
        print("ç¯„ä¾‹:")
        print("  python npy_format_read.py camera_matrix.npy")
        print("  python npy_format_read.py ./calibration_data/")
        return
    
    target_path = sys.argv[1]
    
    if os.path.isfile(target_path):
        reader.analyze_file(target_path)
    elif os.path.isdir(target_path):
        reader.analyze_directory(target_path)
    else:
        print(f"éŒ¯èª¤: è·¯å¾‘ä¸å­˜åœ¨ - {target_path}")

if __name__ == "__main__":
    main()